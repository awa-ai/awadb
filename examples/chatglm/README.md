# 基于Awadb构建你的本地知识库，并结合大语言模型LLM的实现

## 介绍
本章参考了[langchain](https://github.com/hwchase17/langchain)的思想，基于向量数据库，对大模型进行长期记忆增强，以及保证本地数据安全。 

提供了基于本地知识库的问答应用，对中文场景与开源模型支持友好、可离线运行的知识库问答解决方案。本项目中 Embedding 默认选用的是 [GanymedeNil/text2vec-large-chinese](https://huggingface.co/GanymedeNil/text2vec-large-chinese/tree/main)，LLM 默认选用的是 [ChatGLM-6b](https://huggingface.co/THUDM/chatglm-6b)。依托上述模型，本项目可实现全部使用**开源**模型**离线私有部署**。

本项目实现原理如下图所示，过程包括加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的`top k`个 -> 匹配出的文本作为上下文和问题一起添加到`prompt`中 -> 提交给`LLM`生成回答。参考[langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM)

![实现原理图](imgs/langchain+chatglm.png)

从文档处理角度来看，实现流程如下

![实现原理图2](imgs/langchain+chatglm2.png)

## Demo

### 以有关三体问题`你知道面壁计划吗，你知道面壁者都有谁吗`为例：

未使用接入本地文档时：

>面壁计划是指爱因斯坦在1921年提出的一个计划，旨在解决数学和物理学中的一些难题，包括狭义相对论和广义相对论等。这个计划被称为“面壁者计划”，因为它是指爱因斯坦在实验室里进行的研究，而不是指他在实际环境中进行的科学研究。
>由于爱因斯坦在二战期间遭受了严重的头部创伤，他的身体健康状况逐渐恶化，他最终在1955年逝世，享年76岁。因此，“面壁者计划”通常指的是他的相对论研究计划。
>在“面壁者计划”中，爱因斯坦提出了一些重要的数学和物理学理论，包括狭义相对论、广义相对论、质能方程、光电效应、波动方程等。他的理论和思想对现代物理学和数学的发展产生了深远的影响。

使用 awadb 构建了本地三体数据库后 ChatGLM 的回答：

>面壁计划是指由联合国行星防御理事会选定的四位面壁者，他们的任务是领导战略计划的制订和执行，并建立一个扑朔迷离的假象迷宫，以推迟敌人判明我方真实战略意图的时间。面壁者将被授予很高的权力，调集和使用地球已有的战争资源中的一部分，但不需要对自己的行为和命令做出解释。面壁计划是一项人类历史上最艰难的使命，所有面壁者将孤独地走过漫长的岁月。

### 以关于本数据库 awadb 的问题`你知道 awadb 是什么吗?`为例：

未使用接入本地文档时：

>抱歉，我不知道awadb是什么。我是一个基于自然语言处理技术的人工智能助手，我的知识来自于已经存储在我的数据库中的大量文本数据。我无法浏览互联网或访问外部信息，因此我可能无法提供有关最新事件或信息的答案。如果您有任何其他问题，我将尽力回答。

增加了 awadb 的 README.md 文件后 ChatGLM 的回答：

>是的，我知道awadb是什么。awadb是一款为大语言模型LLM打造的向量数据库，用于存储和快速搜索模型编码后的向量，帮助打造基于个人知识库的大模型应用。它是基于C语言开发的，并提供Python接口，可以直接通过pip安装。awadb支持OpenAI, Llama, Vicuna, Alpaca, ChatGLM, Dolly等模型，以及LangChain库
