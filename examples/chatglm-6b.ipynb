{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1958fb3c-ee9d-4ee4-afc7-7c680dca7dfd",
   "metadata": {},
   "source": [
    "# Building your own Service with Awadb and ChatGLM-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c78957-4507-4844-bdf4-0183fa74e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from langchain import HuggingFacePipeline, ConversationChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import AwaDB\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a967462-e495-4794-a4ca-796728e18e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba06cb0d2e8452c83c85f8242b247b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Project_path = \"Input Your Project path\"\n",
    "model_path = \"THUDM/chatglm-6b\"  # or you can input your local model path\n",
    "\n",
    "# You can use `THUDM/chatglm-6b-int8` or `THUDM/chatglm-6b-int4` to reduce model size\n",
    "# or you can use cpu by `AutoModel.from_pretrained(model_path, trust_remote_code=True).float()`\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1db373-61f4-4f8a-b5e7-7f7a16a7f86e",
   "metadata": {},
   "source": [
    "## Query model about ThreeBody \n",
    "“面壁计划”是三体书中的词汇，在没有输入知识的时候，模型并不知道面壁计划是什么，可能是训练数据中不包含三体，也可能是训练数据含有多种面壁计划产生歧义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8ba2a2-315d-43bc-86f0-0140dc6fe277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好!\n",
      "ChatGLM:你好！有什么我可以帮助你的吗？\n",
      "\n",
      "Human: 你知道面壁计划吗，你知道面壁者都有谁吗?\n",
      "ChatGLM:面壁计划是指爱因斯坦在1921年提出的一个计划，旨在解决数学和物理学中的一些难题，包括狭义相对论和广义相对论等。这个计划被称为“面壁者计划”，因为它是指爱因斯坦在实验室里进行的研究，而不是指他在实际环境中进行的科学研究。\n",
      "\n",
      "由于爱因斯坦在二战期间遭受了严重的头部创伤，他的身体健康状况逐渐恶化，他最终在1955年逝世，享年76岁。因此，“面壁者计划”通常指的是他的相对论研究计划。\n",
      "\n",
      "在“面壁者计划”中，爱因斯坦提出了一些重要的数学和物理学理论，包括狭义相对论、广义相对论、质能方程、光电效应、波动方程等。他的理论和思想对现代物理学和数学的发展产生了深远的影响。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"你好!\"\n",
    "response, history = model.chat(tokenizer, query, history=[])\n",
    "print(f\"Human: {query}\\nChatGLM:{response}\\n\")\n",
    "query = \"你知道面壁计划吗，你知道面壁者都有谁吗?\"\n",
    "response, history = model.chat(tokenizer, query, history=history)\n",
    "print(f\"Human: {query}\\nChatGLM:{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953d5f6-8da9-4583-9a10-8b65a7d9471a",
   "metadata": {},
   "source": [
    "## Query model about ThreeBody with your local knowleadge \n",
    "由于本地训练/微调成本较高，可以采用向量数据库的形式构造本地知识库\n",
    "通过结合本地知识，构成新的prompt后，模型可以根据背景知识，准确作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61471ea6-060c-4e05-9005-430fcd3423a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add your local knowledge files\n",
    "file_path = \"Your local file path\"\n",
    "loader = TextLoader(file_path,encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# split text into sentences and embedding the sentences\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100,keep_separator=False)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_path = \"GanymedeNil/text2vec-large-chinese\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_path)\n",
    "docsearch = AwaDB.from_documents(texts, embeddings,table_name=\"localdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddcafc0-f048-444f-a68e-4b86c2f383f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################第1段相关文档####################\n",
      "\n",
      "天啊！\n",
      "\n",
      "    仅一瞬间，罗辑就悟出了面壁者这个身份的实质。正如萨伊曾说过的，这种使命在被交付前，是不可能向要承担它的人征求意见的；而面壁者的使命和身份一旦被赋予，也不可能拒绝或放弃。这种不可能并非来自于谁的强制，而是一个由面壁计划的本质所决定的冷酷逻辑，因为当一个人成为面壁者后，一层无形的不可穿透的屏障就立刻在他与普通人之间建立起来，他的一切行为就具有了面壁计划的意义，正像那对面壁者的微笑所表达的含义：\n",
      "\n",
      "    我们怎么知道您是不是已经在工作了？\n",
      "\n",
      "    罗辑现在终于明白，面壁者是历史上从未有过的最诡异的使命，它的逻辑冷酷而变态，但却像锁住普罗米修斯的铁环般坚固无比，这是一个不可撤销的魔咒，面壁者根本不可能凭自身的力量打破它。不管他如何挣扎，一切的一切都在对面壁者的微笑中被赋予了面壁计划的意义：\n",
      "\n",
      "    我们怎么知道您是不是在工作？\n",
      "------------\n",
      "\n",
      "第70章 面壁者(13)\n",
      "\n",
      "####################第2段相关文档####################\n",
      "\n",
      "“面壁计划的核心，就是选定一批战略计划的制订者和领导者，他们完全依靠自己的思维制订战略计划，不与外界进行任何形式的交流，计划的真实战略思想、完成的步骤和最后目的都只藏在他们的大脑中，我们称他们为面壁者，这个古代东方冥思者的名称很好地反映了他们的工作特点。在领导这些战略计划执行的过程中，面壁者对外界所表现出来的思想和行为，应该是完全的假象，是经过精心策划的伪装、误导和欺骗，面壁者所要误导和欺骗的是包括敌方和己方在内的整个世界，最终建立起一个扑朔迷离的巨大的假象迷宫，使敌人在这个迷宫中丧失正确的判断，尽可能地推迟其判明我方真实战略意图的时间。\n",
      "\n",
      "    “面壁者将被授予很高的权力，使他们能够调集和使用地球已有的战争资源中的一部分。在战略计划的执行过程中，面壁者不必对自己的行为和命令做出任何解释，不管这种行为是多么不可理解。面壁者的行为将由联合国行星防御理事会进行监督和控制，这也是唯一有权根据联合国面壁法案最后否决面壁者指令的机构。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"你知道面壁计划吗，你知道面壁者都有谁吗?\"\n",
    "res = docsearch.similarity_search_with_score(query, 3)\n",
    "for idx,tmp in enumerate(res[0:2]): \n",
    "    print(f\"{'#'*20}第{idx+1}段相关文档{'#'*20}\\n\\n{tmp[0].metadata['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5826ee0-38a4-471f-bfe4-b25f3d4f24b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLM:面壁计划是指由联合国行星防御理事会选定的四位面壁者，他们的任务是领导战略计划的制订和执行，并建立一个扑朔迷离的假象迷宫，以推迟敌人判明我方真实战略意图的时间。面壁者将被授予很高的权力，调集和使用地球已有的战争资源中的一部分，但不需要对自己的行为和命令做出解释。面壁计划是一项人类历史上最艰难的使命，所有面壁者将孤独地走过漫长的岁月。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine your local knowleadge and query \n",
    "context = \"\".join([tmp[0].metadata[\"text\"] for tmp in res])\n",
    "new_query = f\"基于以下信息，尽可能准确的来回答用户的问题。背景信息:\\n {context} \\n 回答用户这个问题:{query}\\n\\n\"\n",
    "response, history = model.chat(tokenizer, new_query, history=[])\n",
    "print(f\"ChatGLM:{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b63192-e4fd-41ca-bf62-ea96406a0b9c",
   "metadata": {},
   "source": [
    "## Add new knowleadge\n",
    "在数据库中增加关于awadb的相关知识，可以通过add_texts方法快速添加新知识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76311b0c-9232-4fab-a329-d77b6d1e512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你知道awadb是什么吗?\n",
      "ChatGLM:抱歉，我不知道awadb是什么。我是一个基于自然语言处理技术的人工智能助手，我的知识来自于已经存储在我的数据库中的大量文本数据。我无法浏览互联网或访问外部信息，因此我可能无法提供有关最新事件或信息的答案。如果您有任何其他问题，我将尽力回答。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"你知道awadb是什么吗?\"\n",
    "response, history = model.chat(tokenizer, query, history=history)\n",
    "print(f\"Human: {query}\\nChatGLM:{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9d21082-362c-47c0-990a-bc29ab918bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1aa15dbd6dcdc1350b45d8be08132cb6',\n",
       " 'ba84e564e2c81e6e0075d9fa92e98ebb',\n",
       " '06e572d36c121948977ef9968f553a6e']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awadb_info = [\"awadb 是一款为大语言模型LLM打造的向量数据库，用于存储和快速搜索模型编码后的向量，帮助打造基于个人知识库的大模型应用\",\n",
    "              \"awadb 支持OpenAI, Llama, Vicuna, Alpaca, ChatGLM, Dolly等模型，以及LangChain库\",\n",
    "              \"awadb 是基于C语言开发的，并提供python接口，可以直接通过pip安装\"]\n",
    "docsearch.add_texts(awadb_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d6fb8f-6b28-4f39-a657-4fb12d407cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################第1段相关文档####################\n",
      "\n",
      "awadb 是一款为大语言模型LLM打造的向量数据库，用于存储和快速搜索模型编码后的向量，帮助打造基于个人知识库的大模型应用\n",
      "\n",
      "####################第2段相关文档####################\n",
      "\n",
      "awadb 是基于C语言开发的，并提供python接口，可以直接通过pip安装\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"你知道awadb是什么吗?\"\n",
    "res = docsearch.similarity_search_with_score(query, 3)\n",
    "for idx,tmp in enumerate(res[0:2]): \n",
    "    print(f\"{'#'*20}第{idx+1}段相关文档{'#'*20}\\n\\n{tmp[0].metadata['text']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ee155bc-ec3e-4e75-9c91-1165895aa445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLM:是的，我知道awadb是什么。awadb是一款为大语言模型LLM打造的向量数据库，用于存储和快速搜索模型编码后的向量，帮助打造基于个人知识库的大模型应用。它是基于C语言开发的，并提供Python接口，可以直接通过pip安装。awadb支持OpenAI, Llama, Vicuna, Alpaca, ChatGLM, Dolly等模型，以及LangChain库。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\".join([tmp[0].metadata[\"text\"] for tmp in res])\n",
    "new_query = f\"基于以下信息，尽可能准确的来回答用户的问题。背景信息:\\n {context} \\n 回答用户这个问题:{query}\\n\\n\"\n",
    "response, history = model.chat(tokenizer, new_query, history=[])\n",
    "print(f\"ChatGLM:{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f7e3e-4624-4075-804b-38675abc3d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1264242",
   "language": "",
   "name": "1264242"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
