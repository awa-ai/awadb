{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1958fb3c-ee9d-4ee4-afc7-7c680dca7dfd",
   "metadata": {},
   "source": [
    "# A demo building your own Model Service with Awadb and langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c78957-4507-4844-bdf4-0183fa74e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from langchain import HuggingFacePipeline, ConversationChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import AwaDB\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "Project_path = \"Input Your Project path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61471ea6-060c-4e05-9005-430fcd3423a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awadb 是一款为大语言模型LLM打造的向量数据库，用于存储和快速搜索模型编码后的向量，帮助打造基于个人知识库的大模型应用\n",
      "awadb 支持OpenAI, Llama, Vicuna, Alpaca, ChatGLM, Dolly等模型，以及LangChain库\n",
      "awadb 是基于C语言开发的，并提供python接口，可以直接通过pip安装\n"
     ]
    }
   ],
   "source": [
    "load_type = torch.float16\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "# Add your local knowledge files\n",
    "file_path=f\"{Project_path}/knowledge.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# split text into sentences and embedding the sentences\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=50,keep_separator=False)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "for text in texts: print(text.page_content)\n",
    "\n",
    "embedding_path = \"GanymedeNil/text2vec-large-chinese\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_path)\n",
    "docsearch = AwaDB.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cddcafc0-f048-444f-a68e-4b86c2f383f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awadb 是基于C语言开发的，并提供python接口，可以直接通过pip安装'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5826ee0-38a4-471f-bfe4-b25f3d4f24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLM models, like OpenAI, Llama, Vicuna, Alpaca, ChatGLM, Dolly...\n",
    "model_path = \"Your own model path\"\n",
    "model = HuggingFacePipeline.from_model_id(model_id=model_path,\n",
    "        task=\"text-generation\",\n",
    "        model_kwargs={\n",
    "                      \"torch_dtype\" : load_type,\n",
    "                      \"low_cpu_mem_usage\" : True,\n",
    "                      \"temperature\": 0.2,\n",
    "                      \"max_length\": 1000,\n",
    "                      \"device_map\": \"auto\",\n",
    "                      \"repetition_penalty\":1.1}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b63192-e4fd-41ca-bf62-ea96406a0b9c",
   "metadata": {},
   "source": [
    "## Query without knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab657c1e-d177-401b-a700-d159271d5b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好, 你知道awadb什么吗\n",
      "AI:  是的, awadb是一个阿拉伯语单词,意思是“幸福”。\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(llm=model, verbose=True)\n",
    "question = \"你好, 你知道awadb什么吗\"\n",
    "output = conversation.predict(input=question)\n",
    "print(f\"Human: {question}\\nAI: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200b3ae-d8ac-440f-afd3-0bbd868d3fdd",
   "metadata": {},
   "source": [
    "## Query with knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af7b309d-cb2c-48a9-b80b-13089ffa43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = (\"基于以下信息，尽可能详细的来回答用户的问题。 \"\n",
    "                   \"背景信息:\\n{context}\\n 回答用户这个问题:{question}\\n\\n\")\n",
    "PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "            llm=model,\n",
    "            chain_type=\"stuff\", \n",
    "            retriever=docsearch.as_retriever(search_kwargs={\"k\": 3}), \n",
    "            chain_type_kwargs=chain_type_kwargs)\n",
    "output = qa.run(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc4f8056-08d7-4733-9dba-4fd74d62b1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你好, 你知道awadb什么吗\n",
      "\n",
      "New Query:\n",
      "基于以下信息，尽可能详细的来回答用户的问题。 背景信息:\n",
      "awadb 是一款为大语言模型LLM打造的向量数据库，用于存储和快速搜索模型编码后的向量，帮助打造基于个人知识库的大模型应用awadb 是基于C语言开发的，并提供python接口，可以直接通过pip安装awadb 支持OpenAI, Llama, Vicuna, Alpaca, ChatGLM, Dolly等模型，以及LangChain库\n",
      "回答用户这个问题:你好, 你知道awadb什么吗\n",
      "\n",
      "\n",
      "AI: awadb 是一个用于存储和快速搜索向量编码后的模型，它可以帮助打造基于个人知识库的大模型应用。它支援OpenAI、Llama、Vicuna、Alpaca、ChatGLM、Dolly等模型，以及LangChain库。\n"
     ]
    }
   ],
   "source": [
    "docs = [doc.page_content for doc in qa._get_docs(question)]\n",
    "new_query = f\"\\n基于以下信息，尽可能详细的来回答用户的问题。 背景信息:\\n{''.join(docs)}\\n回答用户这个问题:{question}\\n\\n\"\n",
    "print(f\"Human: {question}\\n\\nNew Query:{new_query}\\nAI: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73aa24a-c9a4-4f22-ac0c-b32c900410a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1236574",
   "language": "",
   "name": "1236574"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
